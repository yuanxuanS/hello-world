{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.DataFrame([['high', 'medium', 'no', 'no'],\n",
    "                    ['high', 'medium', 'yes', 'no'],\n",
    "                    ['high', 'high', 'no', 'yes'],\n",
    "                    ['high', 'high', 'no', 'yes'],\n",
    "                    ['low', 'high', 'no', 'no'],\n",
    "                    ['medium', 'medium', 'yes', 'yes'],\n",
    "                    ['medium', 'high', 'yes', 'no']],\n",
    "                   index=['sunny', 'sunny','cloudy', 'rainy', 'rainy', 'sunny', 'cloudy'],\n",
    "                   columns=['temperature', 'humidity', 'windy?', 'Basketball?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.name='weather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy?</th>\n",
       "      <th>Basketball?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sunny</th>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunny</th>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudy</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainy</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainy</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunny</th>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudy</th>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature humidity windy? Basketball?\n",
       "weather                                        \n",
       "sunny          high   medium     no          no\n",
       "sunny          high   medium    yes          no\n",
       "cloudy         high     high     no         yes\n",
       "rainy          high     high     no         yes\n",
       "rainy           low     high     no          no\n",
       "sunny        medium   medium    yes         yes\n",
       "cloudy       medium     high    yes          no"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    '''计算熵\n",
    "    p: a list of probility'''\n",
    "    entro = 0\n",
    "    for i in list(p):\n",
    "        entro -= i * np.log2(i)\n",
    "    return entro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gain(par_e, son_p, son_e):\n",
    "    '''计算信息增益：父节点的熵 - 子节点的归一化熵\n",
    "    par_e, son_p, son_e\n",
    "    父节点的熵，子节点的概率, 子节点的对应熵'''\n",
    "    son_sum = 0\n",
    "    for sp, se in zip(son_p, son_e):\n",
    "        son_sum += sp * se\n",
    "    return par_e - son_sum    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020244207153756077"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gain(entropy([3/7, 4/7]), [3/7, 2/7, 2/7], [entropy([1/3, 2/3]), entropy([0.5, 0.5]), entropy([0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_Gain(index, par_e, index_gain_cal):\n",
    "    '''返回最大Gain的index\n",
    "    index: 属性指标的list\n",
    "    index_gain_cal: list, 计算对应属性的gain的message'''\n",
    "    index_gain = []\n",
    "    for gain in index_gain_cal:\n",
    "        son_p, son_e = gain   # list的unpack用直接= 就可 a, b = [1, 2], 和zip不同\n",
    "        index_gain = index_gain + [Gain(par_e, son_p, son_e)]\n",
    "    index_gain = np.array(index_gain)\n",
    "    print(index_gain)\n",
    "    sort = index_gain.argsort()  # 得到的是从小到大排序后的元素的原来的索引值\n",
    "    print(sort)\n",
    "    return index[sort[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['weather', 'temperature', 'humidity', 'windy?']\n",
    "weather_cal = [[3/7, 2/7, 2/7], [entropy([1/3, 2/3]), entropy([0.5, 0.5]), entropy([0.5, 0.5])]]\n",
    "temp_cal = [[4/7, 1/7, 2/7], [entropy([1/2, 1/2]), entropy([1]), entropy([1/2, 1/2])]]\n",
    "hum_cal = [[3/7, 4/7], [entropy([1/3, 2/3]), entropy([1/2, 1/2])]]\n",
    "windy_cal = [[3/7, 4/7], [entropy([1/3, 2/3]), entropy([1/2, 1/2])]]\n",
    "par_e = entropy([3/7, 4/7])\n",
    "cal = [weather_cal, temp_cal, hum_cal, windy_cal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02024421 0.12808528 0.02024421 0.02024421]\n",
      "[0 2 3 1]\n"
     ]
    }
   ],
   "source": [
    "parent_node = max_Gain(index, par_e, cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather', 'humidity', 'windy?']\n"
     ]
    }
   ],
   "source": [
    "high_temp_p = [1/2, 1/2]\n",
    "par_e2 = entropy(high_temp_p)\n",
    "index2 = index[:]\n",
    "index2.remove('temperature')  # 。remove在原list操作，返回None\n",
    "print(index2)\n",
    "high_temp_weather = [[2/4, 1/4, 1/4], [entropy([1]), entropy([1]), entropy([1])]]\n",
    "high_temp_hum = [[1/2, 1/2], [entropy([1]), entropy([1])]]\n",
    "high_temp_windy = [[3/4, 1/4], [entropy([1/3, 2/3]), entropy([1])]]\n",
    "cal_high_temp = [high_temp_weather, high_temp_hum, high_temp_windy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.31127812]\n",
      "[2 0 1]\n",
      "The first node in 1 level is humidity\n"
     ]
    }
   ],
   "source": [
    "level1_first_node = max_Gain(index2, par_e2, cal_high_temp)  # 在根据 temperature分类后得到的结果，重新计算打球概率，再计算\n",
    "print('The first node in 1 level is {}'.format(level1_first_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART 分类树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART 分类树准确率： 0.9800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "# 准备数据集\n",
    "iris = load_iris()\n",
    "# 获取特征和分类标识\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "# 随机抽取作为测试集和训练集\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33)\n",
    "# 创建CART决策树\n",
    "clf = DecisionTreeClassifier(criterion='gini')  # 基尼系数作为划分标准\n",
    "# 拟合分类器\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "# 用该分类器做预测\n",
    "test_predict = clf.predict(test_features)\n",
    "# 比较预测结果和测试集\n",
    "score = accuracy_score(test_labels, test_predict)\n",
    "print('CART 分类树准确率： %.4lf' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART 回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# \n",
    "boston = load_boston()\n",
    "print(boston.feature_names)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归树二乘偏差均值：22.669700598802397\n",
      "回归树绝对值偏差均值： 2.940119760479042\n"
     ]
    }
   ],
   "source": [
    "features, prices = boston.data, boston.target\n",
    "train_features, test_features, train_price, test_price = train_test_split(features, prices, test_size=0.33)\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr = dtr.fit(train_features, train_price)\n",
    "# 进行预测\n",
    "price_predict = dtr.predict(test_features)\n",
    "# 评价预测结果\n",
    "print(\"回归树二乘偏差均值：{}\".format(mean_squared_error(test_price, price_predict)))\n",
    "print(\"回归树绝对值偏差均值： {}\".format(mean_absolute_error(test_price, price_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手写数据集分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归树二乘偏差均值： 3.414141414141414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "features, labels = digits.data, digits.target\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.33)\n",
    "dtc =  DecisionTreeClassifier()\n",
    "dtc = dtc.fit(train_features, train_labels)\n",
    "predict_labels = dtc.predict(test_features)\n",
    "print(\"回归树二乘偏差均值： {}\".format(mean_squared_error(test_labels, predict_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('E:/dplrn/Titanic_Data-master/Titanic_Data-master/train.csv')\n",
    "test_data = pd.read_csv('E:/dplrn/Titanic_Data-master/Titanic_Data-master/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据\n",
    "#print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(test_data.info())\n",
    "train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0     NaN\n",
      "1     C85\n",
      "2     NaN\n",
      "3    C123\n",
      "4     NaN\n",
      "Name: Cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(train_data.Age, train_data.Fare)\n",
    "#print(train_data.isnull().any())\n",
    "print(train_data.Cabin.isnull().any())\n",
    "#print(train_data.Cabin.isnull() / len(train_data.Cabin))\n",
    "print(train_data.Cabin.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如何监测出nan存在，个数，比例等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_nan(data, columns):\n",
    "    '''监测是否有NaN\n",
    "    columns: 要检测的列名'''\n",
    "    for c in columns:\n",
    "        if data[c].isnull().any() == True:\n",
    "            count = data[c].isnull().sum()   # 统计该列na值数量\n",
    "            p = count / data.shape[0]     # 统计na值占比   DataFrame基本attr\n",
    "            print('{} column has {} NaN data, count for {}.'.format(c, count,  p))\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age column has 177 NaN data, count for 0.19865319865319866.\n",
      "Cabin column has 687 NaN data, count for 0.7710437710437711.\n",
      "Embarked column has 2 NaN data, count for 0.002244668911335578.\n"
     ]
    }
   ],
   "source": [
    "has_nan(train_data, ['Pclass','Name','Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       7 non-null      float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 192.0 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [np.nan, 1, 1, 3, 4, 3, 4, 4]\n",
    "t = pd.DataFrame(t)\n",
    "t.sum()\n",
    "t.info()\n",
    "t.describe()\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗\n",
    "train_data.Age.fillna(train_data.Age.mean(), inplace=True)\n",
    "test_data.Age.fillna(train_data.Age.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cabin缺失值很多，无法补齐；\n",
    "# Embarked 缺失值少\n",
    "train_data.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Embarked.fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.Embarked.fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.Fare.fillna(test_data.Fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征选择\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data['Survived']\n",
    "test_features = test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#has_nan(train_labels, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\software\\anaco\\lib\\site-packages\\pandas\\core\\frame.py:1485: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DictVectorizer' object has no attribute 'vocabulary_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-281-20a8ba41651b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mte2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaco\\lib\\site-packages\\sklearn\\feature_extraction\\_dict_vectorizer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m             \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tosequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mXa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DictVectorizer' object has no attribute 'vocabulary_'"
     ]
    }
   ],
   "source": [
    "# string处理:矩阵化\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dvec = DictVectorizer(sparse=False)\n",
    "tr2 = dvec.transform(train_features.to_dict(orient='record'))\n",
    "te2 = dvec.transform(test_features.to_dict(orient='record'))\n",
    "print(dvec.feature_names_)\n",
    "train_features = dvec.fit_transform(train_features.to_dict(orient='record'))\n",
    "test_features = dvec.fit_transform(test_features.to_dict(orient='record'))\n",
    "print(dvec.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建模，训练，预测\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ID3 决策树\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "predict_labels = clf.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 准确率为 0.982043\n"
     ]
    }
   ],
   "source": [
    "# 模型评估, 用训练集\n",
    "acc = round(clf.score(train_features, train_labels), 6)\n",
    "print(\"score 准确率为 {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score 准确率 ：0.7721863034335572\n"
     ]
    }
   ],
   "source": [
    "# 用k折交叉验证评估模型\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"cross_val_score 准确率 ：{}\".format(np.mean(cross_val_score(clf, train_features, train_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
